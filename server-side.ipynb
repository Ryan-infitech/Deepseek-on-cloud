{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t3LK19tPNExg"
      },
      "outputs": [],
      "source": [
        "pip install flask flask-cors requests pyngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G7RX6t8DOiwd"
      },
      "outputs": [],
      "source": [
        "pip install transformers accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xZ0U-D3OPI1A"
      },
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "!apt-get update && apt-get install -y curl\n",
        "\n",
        "# Download and install Ollama\n",
        "!curl -fsSL https://ollama.com/install.sh | sh\n",
        "\n",
        "# Download the model (this might take some time)\n",
        "!ollama pull deepseek-r1:1.5b\n",
        "\n",
        "# Start Ollama server in background\n",
        "!ollama serve &\n",
        "\n",
        "# Wait for server to start\n",
        "import time\n",
        "time.sleep(10)\n",
        "\n",
        "# Main chatbot\n",
        "import requests\n",
        "import json\n",
        "from google.colab import output\n",
        "output.clear()\n",
        "\n",
        "class OllamaAPI:\n",
        "    def __init__(self, base_url=\"http://localhost:11434\"):\n",
        "        self.base_url = base_url\n",
        "\n",
        "    def generate(self, model=\"deepseek-r1:1.5b\", prompt=\"\", stream=False):\n",
        "        \"\"\"\n",
        "        Generate response using Ollama API\n",
        "        \"\"\"\n",
        "        url = f\"{self.base_url}/api/generate\"\n",
        "        data = {\n",
        "            \"model\": model,\n",
        "            \"prompt\": prompt,\n",
        "            \"stream\": stream,\n",
        "            \"options\": {\n",
        "                \"temperature\": 0.7,\n",
        "                \"top_p\": 0.9,\n",
        "                \"top_k\": 40\n",
        "            }\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            response = requests.post(url, json=data)\n",
        "            response.raise_for_status()\n",
        "            return response.json()['response']\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            return f\"Error: {str(e)}\"\n",
        "\n",
        "def main():\n",
        "    print(\"Initializing DeepSeek chatbot di Google Colab...\")\n",
        "    print(\"Memastikan Ollama server berjalan...\")\n",
        "\n",
        "    # Initialize Ollama API\n",
        "    ollama = OllamaAPI()\n",
        "\n",
        "    print(\"\\nChatbot siap! (ketik 'exit' untuk keluar)\")\n",
        "    print(\"----------------------------------------\")\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"\\nAnda: \")\n",
        "\n",
        "        if user_input.lower() == 'exit':\n",
        "            print(\"Chatbot: Terima kasih telah mengobrol! Sampai jumpa!\")\n",
        "            break\n",
        "\n",
        "        # Generate response\n",
        "        response = ollama.generate(prompt=user_input)\n",
        "        print(f\"\\nChatbot: {response}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Stop above this, then run the below code to get the ngrok link"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kc-Ym1mclXUv"
      },
      "outputs": [],
      "source": [
        "from flask import Flask, request, jsonify\n",
        "from flask_cors import CORS\n",
        "import requests\n",
        "from pyngrok import ngrok\n",
        "import time\n",
        "import subprocess\n",
        "import os\n",
        "\n",
        "app = Flask(__name__)\n",
        "CORS(app)\n",
        "\n",
        "class OllamaAPI:\n",
        "    def __init__(self, base_url=\"http://127.0.0.1:11434\"):\n",
        "        self.base_url = base_url\n",
        "        self._ensure_ollama_running()\n",
        "\n",
        "    def _ensure_ollama_running(self):\n",
        "        max_retries = 3\n",
        "        for attempt in range(max_retries):\n",
        "            try:\n",
        "                requests.get(f\"{self.base_url}/api/tags\")\n",
        "                print(\"Ollama server is already running!\")\n",
        "                return\n",
        "            except requests.exceptions.ConnectionError:\n",
        "                if attempt == 0:\n",
        "                    print(\"Starting Ollama server...\")\n",
        "                    subprocess.Popen([\"ollama\", \"serve\"],\n",
        "                                   stdout=subprocess.PIPE,\n",
        "                                   stderr=subprocess.PIPE)\n",
        "                time.sleep(5)  \n",
        "        raise Exception(\"Failed to start Ollama server after multiple attempts\")\n",
        "\n",
        "    def generate(self, prompt, model=\"deepseek-r1:1.5b\"):\n",
        "        if not prompt.strip():\n",
        "            return \"Please provide a valid input.\"\n",
        "\n",
        "        url = f\"{self.base_url}/api/generate\"\n",
        "        data = {\n",
        "            \"model\": model,\n",
        "            \"prompt\": prompt,\n",
        "            \"stream\": False,  # Disable streaming for simpler handling\n",
        "            \"options\": {\n",
        "                \"temperature\": 0.7,\n",
        "                \"top_p\": 0.9,\n",
        "                \"top_k\": 40,\n",
        "                \"timeout\": 30  # timeout setting\n",
        "            }\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            response = requests.post(url, json=data, timeout=60)  # Increased timeout\n",
        "            response.raise_for_status()\n",
        "            return response.json().get('response', 'No response generated')\n",
        "        except requests.exceptions.Timeout:\n",
        "            return \"Request timed out. Please try again.\"\n",
        "        except Exception as e:\n",
        "            return f\"Error: {str(e)}\"\n",
        "\n",
        "# Initial Ollama API\n",
        "ollama = OllamaAPI()\n",
        "\n",
        "@app.route('/chat', methods=['POST'])\n",
        "def chat():\n",
        "    try:\n",
        "        data = request.json\n",
        "        prompt = data.get('prompt', '').strip()\n",
        "\n",
        "        if not prompt:\n",
        "            return jsonify({'error': 'No prompt provided'}), 400\n",
        "\n",
        "        response = ollama.generate(prompt)\n",
        "        return jsonify({'response': response})\n",
        "    except Exception as e:\n",
        "        return jsonify({'error': f'Server error: {str(e)}'}), 500\n",
        "\n",
        "def main():\n",
        "    # Ngrok\n",
        "    ngrok.set_auth_token(\"YOUR-NGROK-AUTH-TOKEN\")\n",
        "    public_url = ngrok.connect(5000)\n",
        "\n",
        "    print(f\"\\n=== SALIN URL INI KE CLIENT.PY DI DEVICE ANDA ===\")\n",
        "    print(f\"URL: {public_url}\")\n",
        "    print(\"===============================================\\n\")\n",
        "\n",
        "    # Run Flask app\n",
        "    app.run(port=5000)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "judoAXaFqZDi"
      },
      "outputs": [],
      "source": [
        "!pkill ollama"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
